{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f65be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from src.Vocab import Vocab\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d858b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-Size: 3760\n",
      "Vocab-Size: 5390\n",
      "Index of '<unk>':  3\n",
      "Index of '<unk>':  3\n",
      "First Word (Index 0):  <pad>\n",
      "First Word (Index 0):  <pad>\n",
      "English:  i\n",
      "France:  je\n",
      "English:  m\n",
      "France:  suis\n",
      "English:  you\n",
      "France:  est\n",
      "English:  re\n",
      "France:  il\n",
      "English:  he\n",
      "France:  vous\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/rec05_small_en_fr.csv\")\n",
    "\n",
    "\n",
    "en_counter = Counter()\n",
    "fr_counter = Counter()\n",
    "for sentence in data[\"EN\"]:\n",
    "    en_counter.update(sentence.split())\n",
    "\n",
    "for sentence in data[\"FR\"]:\n",
    "    fr_counter.update(sentence.split())\n",
    "\n",
    "vocabulary_en = Vocab()\n",
    "vocabulary_fr = Vocab()\n",
    "vocabulary_en.build(en_counter)\n",
    "vocabulary_fr.build(fr_counter)\n",
    "\n",
    "\n",
    "print(f\"Vocab-Size: {len(vocabulary_en)}\")\n",
    "print(f\"Vocab-Size: {len(vocabulary_fr)}\")\n",
    "print(\"Index of '<unk>': \", vocabulary_en.word2idx[\"<unk>\"])\n",
    "print(\"Index of '<unk>': \", vocabulary_fr.word2idx[\"<unk>\"])\n",
    "print(f\"First Word (Index 0): \", vocabulary_en.idx2word[0])\n",
    "print(f\"First Word (Index 0): \", vocabulary_fr.idx2word[0])\n",
    "for i in range(5, 10):\n",
    "    print(\"English: \", vocabulary_en.idx2word[i])\n",
    "    print(\"France: \", vocabulary_fr.idx2word[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb5d623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i m at a loss for words .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"EN\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc88c72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 6, 28, 11, 702, 25, 517, 4, 2]\n",
      "['i', 'm', 'at', 'a', 'loss', 'for', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = data[\"EN\"][0]\n",
    "sentence_idx = vocabulary_en.sentence_to_idx(sentence)\n",
    "print(sentence_idx)\n",
    "sentece_words = vocabulary_en.idx_to_sentence(sentence_idx)\n",
    "print(sentece_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e739f27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8585bad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 6, 28, 11, 702, 25, 517, 4, 2]\n",
      "[1, 29, 20, 1078, 105, 801, 4, 2]\n",
      "['i', 'm', 'at', 'a', 'loss', 'for', 'words', '.']\n",
      "['j', 'en', 'perds', 'mes', 'mots', '.']\n"
     ]
    }
   ],
   "source": [
    "from src.Translation_Data import Translation_Data, collate\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "translation_set = Translation_Data(data, vocabulary_en, vocabulary_fr)\n",
    "\n",
    "input_tensor, output_tensor = translation_set[0]\n",
    "print(input_tensor.tolist())\n",
    "print(output_tensor.tolist())\n",
    "\n",
    "print(vocabulary_en.idx_to_sentence(input_tensor.tolist()))\n",
    "print(vocabulary_fr.idx_to_sentence(output_tensor.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1927e93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape: torch.Size([2, 3])\n",
      "output.shape: torch.Size([2, 4])\n",
      "input:\n",
      " tensor([[1, 5, 6],\n",
      "        [1, 3, 0]])\n",
      "output:\n",
      " tensor([[1, 7, 8, 2],\n",
      "        [1, 4, 2, 0]])\n",
      "input_mask:\n",
      " tensor([[ True,  True,  True],\n",
      "        [ True,  True, False]])\n",
      "output_mask:\n",
      " tensor([[ True,  True,  True,  True],\n",
      "        [ True,  True,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "batch = [\n",
    "    (torch.tensor([1, 5, 6], dtype=torch.long),\n",
    "     torch.tensor([1, 7, 8, 2], dtype=torch.long)),\n",
    "    (torch.tensor([1, 3], dtype=torch.long),\n",
    "     torch.tensor([1, 4, 2], dtype=torch.long)),\n",
    "]\n",
    "\n",
    "pad_idx = 0 \n",
    "\n",
    "out = collate(batch, special_idx=pad_idx)\n",
    "\n",
    "print(\"input.shape:\",  out[\"input\"].shape)    \n",
    "print(\"output.shape:\", out[\"output\"].shape)  \n",
    "\n",
    "print(\"input:\\n\",  out[\"input\"])\n",
    "print(\"output:\\n\", out[\"output\"])\n",
    "\n",
    "print(\"input_mask:\\n\",  out[\"input_mask\"])\n",
    "print(\"output_mask:\\n\", out[\"output_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "237ec2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used:  mps\n",
      "Train batch shapes after moving to device: input=torch.Size([32, 11]), output=torch.Size([32, 11])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Device used: \", device)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    translation_set, batch_size=32, shuffle=True, collate_fn=lambda batch: collate(batch, special_idx=vocabulary_en.word2idx[\"<pad>\"])\n",
    ")\n",
    "\n",
    "# Smoke test: fetch one batch and move to device\n",
    "batch = next(iter(train_loader))\n",
    "input_batch = batch[\"input\"].to(device)\n",
    "output_batch = batch[\"output\"].to(device)\n",
    "input_mask  = batch[\"input_mask\"].to(device)\n",
    "output_mask  = batch[\"output_mask\"].to(device)\n",
    "print(f\"Train batch shapes after moving to device: input={input_batch.shape}, output={output_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43811d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64460940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
